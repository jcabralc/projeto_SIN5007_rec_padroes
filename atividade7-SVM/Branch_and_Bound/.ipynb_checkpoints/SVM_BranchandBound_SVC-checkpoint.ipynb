{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 7 - Classificador SVM\n",
    "\n",
    "# Branch and Bound - Sem Normalização\n",
    "\n",
    "# Algoritmo SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM:\n",
    "\n",
    "● Realizar validação cruzada k=10 para testar SVMs utilizando:\n",
    "    - todas a características\n",
    "    - apenas com os componentes principais\n",
    "    - apenas com as características selecionadas pelo selecionador 1\n",
    "    - apenas com as características selecionadas pelo selecionador 2 (opcional)\n",
    "\n",
    "Em cada um, calibrar os parâmetros (kernel, parâmetros do kernel e C) e reportar os valores médios de precisão, revocação e acurácia para o que apresentou melhor acurácia (com os respectivos intervalos de confiança)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "\n",
    "#normalizacao\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Modelagem\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Classificador\n",
    "from sklearn.svm import SVC # C-Support Vector Classification\n",
    "from sklearn.svm import LinearSVC # Linear Support Vector Classification\n",
    "from sklearn.svm import NuSVC # Nu-Support Vector Classification\n",
    "\n",
    "\n",
    "# Balanceamento das classes\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Validação\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from scipy import stats as st\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "random_state=5007\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(858, 36)\n"
     ]
    }
   ],
   "source": [
    "# importa dataset\n",
    "\n",
    "df = read_csv('../../data/kag_risk_factors_cervical_cancer.csv')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características selecionadas pelo Branch and Bound na atividade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecionadas_BB = ['Age','Number of sexual partners',\n",
    "                   'First sexual intercourse', 'Num of pregnancies',\n",
    "                   'Smokes (years)','Smokes']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substituindo ? por NAN\n",
    "df.replace('?', np.NAN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma as feature em numericas\n",
    "df_processed = df.apply(pd.to_numeric, errors=\"ignore\")\n",
    "\n",
    "# Resultado final com as devidas alteracoes\n",
    "#df_processed.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminação (ou não) de instâncias com missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para features continuas --> preenche com a mediana (para nao ter muito impacto com outliers)\n",
    "\n",
    "Hipotese:\n",
    " - Para features categoricas --> preenche com o valor mais frequente\n",
    " \n",
    "No decorrer dos experimentos validar se a hipotese é aceita ou não.\n",
    "\n",
    "(Uma alternativa seria imputar os valores pelo moda (valor mais frequente), que provavelmente é uma solução ruim, pois a resposta verdadeira pode estar correlacionada com a probabilidade de um valor estar ausente. Pois isso teremos um bias, pois esses valores são privados e a pessoa pode escolher não divulga-los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_feat = ['Age',\n",
    "                   'Number of sexual partners',\n",
    "                   'First sexual intercourse',\n",
    "                   'Num of pregnancies', \n",
    "                   'Smokes (years)',\n",
    "                   'Smokes (packs/year)',\n",
    "                   'Hormonal Contraceptives (years)',\n",
    "                   'IUD (years)',\n",
    "                   'STDs (number)',\n",
    "                   'STDs: Number of diagnosis',\n",
    "                   'STDs: Time since first diagnosis',\n",
    "                   'STDs: Time since last diagnosis'] \n",
    "\n",
    "binary_feat = [  'Smokes',\n",
    "                 'Hormonal Contraceptives',\n",
    "                 'IUD',\n",
    "                 'STDs',\n",
    "                 'STDs:condylomatosis',\n",
    "                 'STDs:cervical condylomatosis',\n",
    "                 'STDs:vaginal condylomatosis',\n",
    "                 'STDs:vulvo-perineal condylomatosis',\n",
    "                 'STDs:syphilis',\n",
    "                 'STDs:pelvic inflammatory disease',\n",
    "                 'STDs:genital herpes',\n",
    "                 'STDs:molluscum contagiosum',\n",
    "                 'STDs:AIDS',\n",
    "                 'STDs:HIV',\n",
    "                 'STDs:Hepatitis B',\n",
    "                 'STDs:HPV',\n",
    "                 'Dx:Cancer',\n",
    "                 'Dx:CIN',\n",
    "                 'Dx:HPV',\n",
    "                 'Dx',\n",
    "                 'Hinselmann',\n",
    "                 'Schiller',\n",
    "                 'Citology']                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = df_processed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preenche com a mediana\n",
    "imp_median = SimpleImputer(missing_values = np.nan, strategy = 'median')\n",
    "df_imp[continuous_feat] = imp_median.fit_transform(df_processed[continuous_feat])\n",
    "\n",
    "# preenche com o valor mais frequente\n",
    "imp_most_freq = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "df_imp[binary_feat] = imp_most_freq.fit_transform(df_processed[binary_feat])\n",
    "\n",
    "#df_imp.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Cross- Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation com dataset DESBALANCEADO\n",
    "\n",
    "def stratified_k_fold(df, k, algoritmo, random_state, grid_params, shuffle=False, shrinking=True):\n",
    "    print('------')\n",
    "    print('Algorimto Utilizado: {}'.format(algoritmo))\n",
    "    print('------')\n",
    "    \n",
    "    # Utilizando todas as features como preditoras\n",
    "    X = df.drop('Biopsy', axis=1)\n",
    "    y = df['Biopsy']\n",
    "    \n",
    "    # quantidade original de classes\n",
    "    count_classes = y.value_counts()\n",
    "    \n",
    "    # Stratified K Fold\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "    skf.get_n_splits(X, y)\n",
    "    print('k = {}, Dataset {} positivas e {} negativas ({:.2f}% x {:.2f}%)'.format(k, count_classes[1], \n",
    "                                                                                 count_classes[0], \n",
    "                                                                                 ((count_classes[1]/len(y))*100), \n",
    "                                                                                 ((count_classes[0]/len(y))*100)))\n",
    "        \n",
    "    # Scores (das futuras metricas)\n",
    "    scores = []\n",
    "    \n",
    "    # coleta os parametros que serao testados\n",
    "    kernels = grid_params.get('kernels')\n",
    "    gamma_range = grid_params.get('gamma_range')\n",
    "    gamma_step = grid_params.get('gamma_step')\n",
    "    C_range = grid_params.get('C_range')\n",
    "    \n",
    "    # Testa varios KERNELS\n",
    "    for kernel in kernels:\n",
    "        print(\"-> Teste Kernel {}\".format(kernel))\n",
    "        \n",
    "        # Testa varios C\n",
    "        for c in C_range:\n",
    "#             print(\"\\t\\tTeste Param C {}\".format(c))\n",
    "        \n",
    "            if kernel in ['rbf', 'poly', 'sigmoid']:\n",
    "                # Testa varios GAMMA\n",
    "                for gamma in list(np.arange(gamma_range[0], gamma_range[1], gamma_step))+['scale', 'auto']:\n",
    "#                     print(\"\\t\\t\\tTeste Param Gamma {}\".format(gamma))\n",
    "                    \n",
    "                    print('-> Criando modelo com params c={}, gamma={}'.format(c, gamma))\n",
    "                    clf = algoritmo(kernel=kernel, gamma=gamma, C=c, verbose=1, shrinking=shrinking)\n",
    "                    \n",
    "                    # Folds\n",
    "                    for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "                        fold_number = fold\n",
    "                        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "                        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "                        # quantidade de classes dentro da fold\n",
    "                        count_classes_fold = y.iloc[test_index].value_counts()\n",
    "                        # proporções\n",
    "                        prop_pos = ((count_classes_fold[1]/count_classes_fold.sum())*100)\n",
    "                        prop_neg = ((count_classes_fold[0]/count_classes_fold.sum())*100)\n",
    "                        print('Fold {}: Pos: {}, Neg: {}, Total: {}, Proporção: {:.2f}% x {:.2f}%'.format(fold_number, \n",
    "                                                                                            count_classes_fold[1],\n",
    "                                                                                            count_classes_fold[0], \n",
    "                                                                                            count_classes_fold.sum(),\n",
    "                                                                                            prop_pos, prop_neg))\n",
    "\n",
    "                        # aplica o classificador\n",
    "                        clf = clf.fit(X_train, y_train)\n",
    "                        #display(clf)\n",
    "\n",
    "                        # predict no dataset de treino \n",
    "                        y_train_preds = clf.predict(X_train)\n",
    "                        # predict no dataset de teste\n",
    "                        y_pred = clf.predict(X_test)\n",
    "\n",
    "                        print(\"\\tNumero de instancias classificadas erradas do total de %d instancias : %d\"\n",
    "                         % (y_test.shape[0], (y_test != y_pred).sum()))\n",
    "                       # print(\"Number of points predicted as Pos: %d\"\n",
    "                       #  % ((y_pred == 1).sum()))\n",
    "\n",
    "                        # Scores do model (utilizados dados nao-balanceados) - dados de teste\n",
    "                        recall = recall_score(y_test, y_pred)\n",
    "                        accuracy = accuracy_score(y_test, y_pred)\n",
    "                        precision = precision_score(y_test, y_pred)\n",
    "                        scores.append([kernel, c, gamma, fold_number, precision, recall, accuracy])\n",
    "\n",
    "            #return np.array(scores)\n",
    "            else:\n",
    "                print('-> Criando modelo com params c={}'.format(c))\n",
    "                clf = algoritmo(kernel=kernel, C=c, verbose=1, shrinking=shrinking)\n",
    "                \n",
    "                # utilizando valor default de gamma\n",
    "                #gamma = clf.gamma # para acompanhamento dos scores\n",
    "                gamma = clf.gamma\n",
    "                \n",
    "                # Folds\n",
    "                for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "                    fold_number = fold\n",
    "                    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "                    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "                    # quantidade de classes dentro da fold\n",
    "                    count_classes_fold = y.iloc[test_index].value_counts()\n",
    "                    # proporções\n",
    "                    prop_pos = ((count_classes_fold[1]/count_classes_fold.sum())*100)\n",
    "                    prop_neg = ((count_classes_fold[0]/count_classes_fold.sum())*100)\n",
    "                    print('Fold {}: Pos: {}, Neg: {}, Total: {}, Proporção: {:.2f}% x {:.2f}%'.format(fold_number, \n",
    "                                                                                        count_classes_fold[1],\n",
    "                                                                                        count_classes_fold[0], \n",
    "                                                                                        count_classes_fold.sum(),\n",
    "                                                                                        prop_pos, prop_neg))\n",
    "                    \n",
    "                    # aplica o classificador\n",
    "                    clf = clf.fit(X_train, y_train)\n",
    "                    #display(clf)\n",
    "\n",
    "                    # predict no dataset de treino \n",
    "                    y_train_preds = clf.predict(X_train)\n",
    "                    # predict no dataset de teste\n",
    "                    y_pred = clf.predict(X_test)\n",
    "                    \n",
    "                    print(\"\\tNumero de instancias classificadas erradas do total de %d instancias : %d\"\n",
    "                     % (y_test.shape[0], (y_test != y_pred).sum()))\n",
    "                   # print(\"Number of points predicted as Pos: %d\"\n",
    "                   #  % ((y_pred == 1).sum()))\n",
    "\n",
    "                    # Scores do model (utilizados dados nao-balanceados) - dados de teste\n",
    "                    recall = recall_score(y_test, y_pred)\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    precision = precision_score(y_test, y_pred)\n",
    "                    scores.append([kernel, c, gamma, fold_number, precision, recall, accuracy])\n",
    "\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation com dataset BALANCEADO (SMOTETomek)\n",
    "\n",
    "def stratified_k_fold_SMOTE(df, k, algoritmo, random_state, grid_params, shuffle=False, shrinking=True):\n",
    "    print('------')\n",
    "    print('Algorimto Utilizado: {}'.format(algoritmo))\n",
    "    print('------')\n",
    "    \n",
    "    # Utilizando todas as features como preditoras\n",
    "    X = df.drop('Biopsy', axis=1)\n",
    "    y = df['Biopsy']\n",
    "    # quantidade original de classes\n",
    "    count_classes = y.value_counts()\n",
    "    # Stratified K Fold\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "    skf.get_n_splits(X, y)\n",
    "    print('k = {}, Dataset (desbalanceado) {} positivas e {} negativas ({:.2f}% x {:.2f}%)'.format(k, count_classes[1], \n",
    "                                                                                 count_classes[0], \n",
    "                                                                                 ((count_classes[1]/len(y))*100), \n",
    "                                                                                 ((count_classes[0]/len(y))*100)))\n",
    "   \n",
    "    # Normalização MinMax\n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    # SMOTETomek\n",
    "    cc = SMOTETomek(random_state=random_state)\n",
    "\n",
    "    # Scores (das futuras metricas)\n",
    "    scores = []\n",
    "    \n",
    "    # coleta os parametros que serao testados\n",
    "    kernels = grid_params.get('kernels')\n",
    "    gamma_range = grid_params.get('gamma_range')\n",
    "    gamma_step = grid_params.get('gamma_step')\n",
    "    C_range = grid_params.get('C_range')\n",
    "    \n",
    "    # Testa varios KERNELS\n",
    "    for kernel in kernels:\n",
    "        print(\"-> Teste Kernel {}\".format(kernel))\n",
    "        \n",
    "        # Testa varios C\n",
    "        for c in C_range:\n",
    "#             print(\"\\t\\tTeste Param C {}\".format(c))\n",
    "        \n",
    "            if kernel in ['rbf', 'poly', 'sigmoid']:\n",
    "                # Testa varios GAMMA\n",
    "                for gamma in list(np.arange(gamma_range[0], gamma_range[1], gamma_step))+['scale', 'auto']:\n",
    "#                     print(\"\\t\\t\\tTeste Param Gamma {}\".format(gamma))\n",
    "                    \n",
    "                    print('-> Criando modelo com params c={}, gamma={}'.format(c, gamma))\n",
    "                    clf = algoritmo(kernel=kernel, gamma=gamma, C=c, verbose=1, shrinking=shrinking)\n",
    "                    \n",
    "                    # Folds\n",
    "                    for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "                        fold_number = fold\n",
    "                        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "                        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "                        \n",
    "                        # Normaliza MinMax para aplicar Smote\n",
    "                        X_train_normalized = minmax_scale.fit_transform(X_train)\n",
    "                        X_train_normalized = pd.DataFrame(X_train_normalized, columns = X.columns.tolist())\n",
    "                        \n",
    "                        # SMOTETomek (apenas os dados de treino)\n",
    "                        print('\\tBalanceando dados de treino fold {}...'.format(fold_number))\n",
    "                        X_train, y_train = cc.fit_resample(X_train_normalized, y_train)\n",
    "                        \n",
    "                        # Retorna para valores não normalizados\n",
    "                        X_train = pd.DataFrame(minmax_scale.inverse_transform(X_train), columns = X.columns.tolist())\n",
    "                        print('\\t\\tFold = {}, Dataset (balanceado) {} positivas e {} negativas ({:.2f}% x {:.2f}%)'.format(fold_number, \n",
    "                                                                                                 y_train.value_counts()[0], \n",
    "                                                                                                 y_train.value_counts()[1], \n",
    "                                                                                                 ((y_train.value_counts()[0]/len(y_train))*100), \n",
    "                                                                                                 ((y_train.value_counts()[1]/len(y_train))*100)))\n",
    "\n",
    "                        # quantidade de classes dentro da fold\n",
    "                        count_classes_fold = y_test.value_counts()\n",
    "                        # proporções\n",
    "                        prop_pos = ((count_classes_fold[1]/count_classes_fold.sum())*100)\n",
    "                        prop_neg = ((count_classes_fold[0]/count_classes_fold.sum())*100)\n",
    "                        print('\\t\\tDados de teste (desbalanceados)')\n",
    "                        print('\\t\\tFold {}: Pos: {}, Neg: {}, Total: {}, Proporção: {:.2f}% x {:.2f}%'.format(fold_number, \n",
    "                                                                                            count_classes_fold[1],\n",
    "                                                                                            count_classes_fold[0], \n",
    "                                                                                            count_classes_fold.sum(),\n",
    "                                                                                            prop_pos, prop_neg))\n",
    "                        # aplica o classificador\n",
    "                        clf = clf.fit(X_train, y_train)\n",
    "                        #display(clf)\n",
    "\n",
    "                        # predict no dataset de treino \n",
    "                        y_train_preds = clf.predict(X_train)\n",
    "                        # predict no dataset de teste\n",
    "                        y_pred = clf.predict(X_test)\n",
    "\n",
    "                        print(\"\\tNumero de instancias classificadas erradas do total de %d instancias : %d\"\n",
    "                         % (y_test.shape[0], (y_test != y_pred).sum()))\n",
    "                       # print(\"Number of points predicted as Pos: %d\"\n",
    "                       #  % ((y_pred == 1).sum()))\n",
    "\n",
    "                        # Scores do model (utilizados dados nao-balanceados) - dados de teste\n",
    "                        recall = recall_score(y_test, y_pred)\n",
    "                        accuracy = accuracy_score(y_test, y_pred)\n",
    "                        precision = precision_score(y_test, y_pred)\n",
    "                        scores.append([kernel, c, gamma, fold_number, precision, recall, accuracy])\n",
    "\n",
    "            #return np.array(scores)\n",
    "            else:\n",
    "                print('-> Criando modelo com params c={}'.format(c))\n",
    "                clf = algoritmo(kernel=kernel, C=c, verbose=1, shrinking=shrinking)\n",
    "                \n",
    "                # utilizando valor default de gamma\n",
    "                #gamma = clf.gamma # para acompanhamento dos scores\n",
    "                gamma = clf.gamma\n",
    "                \n",
    "                # Folds\n",
    "                for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "                    fold_number = fold\n",
    "                    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "                    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "                    # Normaliza MinMax para aplicar Smote\n",
    "                    X_train_normalized = minmax_scale.fit_transform(X_train)\n",
    "                    X_train_normalized = pd.DataFrame(X_train_normalized, columns = X.columns.tolist())\n",
    "\n",
    "                    # SMOTETomek (apenas os dados de treino)\n",
    "                    print('\\tBalanceando dados de treino fold {}...'.format(fold_number))\n",
    "                    X_train, y_train = cc.fit_resample(X_train_normalized, y_train)\n",
    "\n",
    "                    # Retorna para valores não normalizados\n",
    "                    X_train = pd.DataFrame(minmax_scale.inverse_transform(X_train), columns = X.columns.tolist())\n",
    "                    print('\\t\\tFold = {}, Dataset (balanceado) {} positivas e {} negativas ({:.2f}% x {:.2f}%)'.format(fold_number, \n",
    "                                                                                             y_train.value_counts()[0], \n",
    "                                                                                             y_train.value_counts()[1], \n",
    "                                                                                             ((y_train.value_counts()[0]/len(y_train))*100), \n",
    "                                                                                             ((y_train.value_counts()[1]/len(y_train))*100)))\n",
    "\n",
    "                    # quantidade de classes dentro da fold\n",
    "                    count_classes_fold = y_test.value_counts()\n",
    "                    # proporções\n",
    "                    prop_pos = ((count_classes_fold[1]/count_classes_fold.sum())*100)\n",
    "                    prop_neg = ((count_classes_fold[0]/count_classes_fold.sum())*100)\n",
    "                    print('\\t\\tDados de teste (desbalanceados)')\n",
    "                    print('\\t\\tFold {}: Pos: {}, Neg: {}, Total: {}, Proporção: {:.2f}% x {:.2f}%'.format(fold_number, \n",
    "                                                                                        count_classes_fold[1],\n",
    "                                                                                        count_classes_fold[0], \n",
    "                                                                                        count_classes_fold.sum(),\n",
    "                                                                                        prop_pos, prop_neg))\n",
    "                    # aplica o classificador\n",
    "                    clf = clf.fit(X_train, y_train)\n",
    "                    #display(clf)\n",
    "\n",
    "                    # predict no dataset de treino \n",
    "                    y_train_preds = clf.predict(X_train)\n",
    "                    # predict no dataset de teste\n",
    "                    y_pred = clf.predict(X_test)\n",
    "\n",
    "                    print(\"\\tNumero de instancias classificadas erradas do total de %d instancias : %d\"\n",
    "                     % (y_test.shape[0], (y_test != y_pred).sum()))\n",
    "                   # print(\"Number of points predicted as Pos: %d\"\n",
    "                   #  % ((y_pred == 1).sum()))\n",
    "\n",
    "                    # Scores do model (utilizados dados nao-balanceados) - dados de teste\n",
    "                    recall = recall_score(y_test, y_pred)\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    precision = precision_score(y_test, y_pred)\n",
    "                    scores.append([kernel, c, gamma, fold_number, precision, recall, accuracy])\n",
    "\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid de Parametros para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_all = {'gamma_range': [1e-4, 10e-1],\n",
    "               'gamma_step': 0.01,\n",
    "               'kernels': ['linear', 'poly', 'rbf', 'sigmoid'],#, 'precomputed'],\n",
    "               'C_range': [1, 10, 100, 1000]\n",
    "              }\n",
    "\n",
    "grid_params_semi = {'gamma_range': [1e-4, 10e-1],\n",
    "               'gamma_step': 0.01,\n",
    "               'kernels': ['linear', 'rbf', 'sigmoid'],#, 'precomputed'],\n",
    "               'C_range': [1, 10, 100, 1000]\n",
    "              }\n",
    "\n",
    "grid_params_linear = {'kernels': ['linear'],\n",
    "                      'C_range': [1, 10, 100, 1000]\n",
    "                     }\n",
    "\n",
    "\n",
    "grid_params_sigmoid = {'kernels': ['sigmoid'],\n",
    "                      'gamma_range': [1e-4, 10e-1],\n",
    "                       'gamma_step': 0.01,\n",
    "                        'C_range': [1, 10, 100, 1000]\n",
    "                       }\n",
    "\n",
    "\n",
    "grid_params_rbf = {'gamma_range': [1e-4, 10e-1],\n",
    "                   'gamma_step': 0.01,\n",
    "                   'kernels': ['rbf'],\n",
    "                   'C_range': [1, 10, 100, 1000]\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando Precisão, Revocação e Acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algortimo-> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of sexual partners</th>\n",
       "      <th>First sexual intercourse</th>\n",
       "      <th>Num of pregnancies</th>\n",
       "      <th>Smokes (years)</th>\n",
       "      <th>Smokes</th>\n",
       "      <th>Biopsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Number of sexual partners  First sexual intercourse  Num of pregnancies  Smokes (years)  Smokes  Biopsy\n",
       "0  18.0                        4.0                      15.0                 1.0             0.0     0.0       0\n",
       "1  15.0                        1.0                      14.0                 1.0             0.0     0.0       0\n",
       "2  34.0                        1.0                      17.0                 1.0             0.0     0.0       0\n",
       "3  52.0                        5.0                      16.0                 4.0            37.0     1.0       0\n",
       "4  46.0                        3.0                      21.0                 4.0             0.0     0.0       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selecionado = df_imp[selecionadas_BB]\n",
    "df_selecionado = df_selecionado.join(df_imp['Biopsy'])\n",
    "\n",
    "df_selecionado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Desbalanceado"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Atenção:\n",
    "\n",
    "Durante o treinamento, por conta do Verbose=1, o algoritmo de otimização detectou que, com alta probabilidade seria possivel acelerar o treinamento colocando -h 0 nos parametros. \n",
    "\n",
    "Basicamente, -h é a heurística cada vez menor, implementada no pacote libsvm que, para alguns dados, reduz significativamente o número de computações necessárias, enquanto em outras, o torna mais lento\n",
    "\n",
    "A mensagem que foi exibida foi: \"Warning: using -h 0 may be faster\"\n",
    "\n",
    "-h == parametro shrinking do SVC\n",
    "\n",
    "Por isso esse parametro é passado a função de cross validation como FALSE (default é True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold com K = 10\n",
      "------\n",
      "Algorimto Utilizado: <class 'sklearn.svm._classes.SVC'>\n",
      "------\n",
      "k = 10, Dataset 55 positivas e 803 negativas (6.41% x 93.59%)\n",
      "-> Teste Kernel linear\n",
      "-> Criando modelo com params c=1\n",
      "Fold 1: Pos: 5, Neg: 81, Total: 86, Proporção: 5.81% x 94.19%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 5\n",
      "Fold 2: Pos: 5, Neg: 81, Total: 86, Proporção: 5.81% x 94.19%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 5\n",
      "Fold 3: Pos: 5, Neg: 81, Total: 86, Proporção: 5.81% x 94.19%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 5\n",
      "Fold 4: Pos: 6, Neg: 80, Total: 86, Proporção: 6.98% x 93.02%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 6\n",
      "Fold 5: Pos: 6, Neg: 80, Total: 86, Proporção: 6.98% x 93.02%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 6\n",
      "Fold 6: Pos: 6, Neg: 80, Total: 86, Proporção: 6.98% x 93.02%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 6\n",
      "Fold 7: Pos: 6, Neg: 80, Total: 86, Proporção: 6.98% x 93.02%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 6\n",
      "Fold 8: Pos: 6, Neg: 80, Total: 86, Proporção: 6.98% x 93.02%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 6\n",
      "Fold 9: Pos: 5, Neg: 80, Total: 85, Proporção: 5.88% x 94.12%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 85 instancias : 5\n",
      "Fold 10: Pos: 5, Neg: 80, Total: 85, Proporção: 5.88% x 94.12%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 85 instancias : 5\n",
      "-> Criando modelo com params c=10\n",
      "Fold 1: Pos: 5, Neg: 81, Total: 86, Proporção: 5.81% x 94.19%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 5\n",
      "Fold 2: Pos: 5, Neg: 81, Total: 86, Proporção: 5.81% x 94.19%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 5\n",
      "Fold 3: Pos: 5, Neg: 81, Total: 86, Proporção: 5.81% x 94.19%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 5\n",
      "Fold 4: Pos: 6, Neg: 80, Total: 86, Proporção: 6.98% x 93.02%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 6\n",
      "Fold 5: Pos: 6, Neg: 80, Total: 86, Proporção: 6.98% x 93.02%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 6\n",
      "Fold 6: Pos: 6, Neg: 80, Total: 86, Proporção: 6.98% x 93.02%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 6\n",
      "Fold 7: Pos: 6, Neg: 80, Total: 86, Proporção: 6.98% x 93.02%\n",
      "[LibSVM]\tNumero de instancias classificadas erradas do total de 86 instancias : 6\n",
      "Fold 8: Pos: 6, Neg: 80, Total: 86, Proporção: 6.98% x 93.02%\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "print('K-Fold com K = {}'.format(k))\n",
    "scores_unbalanced = pd.DataFrame(stratified_k_fold(df_selecionado, k, SVC, random_state, grid_params_semi, \n",
    "                                                   shuffle=False, shrinking=False))\n",
    "scores_unbalanced = scores_unbalanced.rename(columns = {0: 'Kernel', 1: 'c', 2: 'Gamma', 3:'Fold', \n",
    "                                                        4: 'Precision', 5: 'Recall', 6: 'Accuracy'}) \n",
    "scores_unbalanced['Algorimto'] = 'SVC'\n",
    "float_cols = ['c', 'Fold', 'Precision', 'Recall', 'Accuracy']# 'Gamma'\n",
    "scores_unbalanced[float_cols] = scores_unbalanced[float_cols].apply(pd.to_numeric, errors='coerce')\n",
    "print('----'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(scores_unbalanced.head())\n",
    "\n",
    "#Salva os Scores\n",
    "scores_unbalanced.to_excel('scores_unbalanced-Branch_and_Bound-Sem_Normalizacao_SVC.xlsx', \n",
    "                           encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "print('K-Fold com K = {}'.format(k))\n",
    "scores_balanced = pd.DataFrame(stratified_k_fold_SMOTE(df_selecionado, k, SVC, random_state, grid_params_semi, \n",
    "                                                   shuffle=False, shrinking=False))\n",
    "scores_balanced = scores_balanced.rename(columns = {0: 'Kernel', 1: 'c', 2: 'Gamma', 3:'Fold', \n",
    "                                                        4: 'Precision', 5: 'Recall', 6: 'Accuracy'}) \n",
    "scores_balanced['Algorimto'] = 'SVC'\n",
    "float_cols = ['c', 'Fold', 'Precision', 'Recall', 'Accuracy']# 'Gamma'\n",
    "scores_balanced[float_cols] = scores_balanced[float_cols].apply(pd.to_numeric, errors='coerce')\n",
    "print('----'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(scores_balanced.head())\n",
    "\n",
    "#Salva os Scores\n",
    "scores_balanced.to_excel('scores_balanced-Branch_and_Bound-Sem_Normalizacao_SVC.xlsx', \n",
    "                           encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando os parâmetros com maior acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_unbalanced = scores_unbalanced.groupby(['Kernel','c','Gamma']).mean().drop('Fold', axis = 1)\n",
    "mean_unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 com maior média\n",
    "display(mean_unbalanced.sort_values(['Accuracy'],ascending=False)[:5])\n",
    "\n",
    "max_alpha_unbalanced = mean_unbalanced['Accuracy'].idxmax()\n",
    "max_alpha_unbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_balanced = scores_balanced.groupby(['Kernel','c','Gamma']).mean().drop('Fold', axis = 1)\n",
    "mean_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 com maior média\n",
    "display(mean_balanced.sort_values(['Accuracy'],ascending=False)[:5])\n",
    "\n",
    "max_alpha_balanced = mean_balanced['Accuracy'].idxmax()\n",
    "max_alpha_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando intervalo de confiança da Acurácia para os melhores parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando apenas folds com os melhores params\n",
    "metrics_unbalanced = scores_unbalanced.loc[scores_unbalanced[(scores_unbalanced['Kernel'] == max_alpha_unbalanced[0]) &\n",
    "                                                             (scores_unbalanced['c'] == max_alpha_unbalanced[1]) &\n",
    "                                                             (scores_unbalanced['Gamma'] == max_alpha_unbalanced[2])].index, ['Accuracy', 'Recall', 'Precision']]\n",
    "mean_unbalanced = np.mean(metrics_unbalanced)\n",
    "\n",
    "# Calculo do ic\n",
    "acc_min_unbalanced, acc_max_unbalanced = st.t.interval(0.95, len(metrics_unbalanced['Accuracy'])-1, loc=mean_unbalanced[0], scale=st.sem(metrics_unbalanced['Accuracy']))  \n",
    "rec_min_unbalanced, rec_max_unbalanced = st.t.interval(0.95, len(metrics_unbalanced['Recall'])-1, loc=mean_unbalanced[1], scale=st.sem(metrics_unbalanced['Recall']))  \n",
    "pre_min_unbalanced, pre_max_unbalanced = st.t.interval(0.95, len(metrics_unbalanced['Precision'])-1, loc=mean_unbalanced[2], scale=st.sem(metrics_unbalanced['Precision']))  \n",
    "\n",
    "\n",
    "print('Acurácia: Média = {:.3f}, IC = [{:.3f}, {:.3f}]'.format(mean_unbalanced[0],acc_min_unbalanced, acc_max_unbalanced))\n",
    "print('Recall: Média = {:.3f}, IC = [{:.3f}, {:.3f}]'.format(mean_unbalanced[1],rec_min_unbalanced, rec_max_unbalanced))\n",
    "print('Precisão: Média = {:.3f}, IC = [{:.3f}, {:.3f}]'.format(mean_unbalanced[2],pre_min_unbalanced, pre_max_unbalanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando apenas folds com os melhores params\n",
    "metrics_balanced = scores_balanced.loc[scores_balanced[(scores_balanced['Kernel'] == max_alpha_balanced[0]) &\n",
    "                                                       (scores_balanced['c'] == max_alpha_balanced[1]) &\n",
    "                                                       (scores_balanced['Gamma'] == max_alpha_balanced[2])].index, ['Accuracy', 'Recall', 'Precision']]\n",
    "mean_balanced = np.mean(metrics_balanced)\n",
    "\n",
    "# Calculo do ic\n",
    "acc_min_balanced, acc_max_balanced  = st.t.interval(0.95, len(metrics_balanced['Accuracy'])-1, loc=mean_balanced[0], scale=st.sem(metrics_balanced['Accuracy']))  \n",
    "rec_min_balanced, rec_max_balanced = st.t.interval(0.95, len(metrics_balanced['Recall'])-1, loc=mean_balanced[1], scale=st.sem(metrics_balanced['Recall']))  \n",
    "pre_min_balanced, pre_max_balanced = st.t.interval(0.95, len(metrics_balanced['Precision'])-1, loc=mean_balanced[2], scale=st.sem(metrics_balanced['Precision']))  \n",
    "\n",
    "\n",
    "print('Acurácia: Média = {:.3f}, IC = [{:.3f}, {:.3f}]'.format(mean_balanced[0],acc_min_balanced, acc_max_balanced))\n",
    "print('Recall: Média = {:.3f}, IC = [{:.3f}, {:.3f}]'.format(mean_balanced[1],rec_min_balanced, rec_max_balanced))\n",
    "print('Precisão: Média = {:.3f}, IC = [{:.3f}, {:.3f}]'.format(mean_balanced[2],pre_min_balanced, pre_max_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/44542112\n",
    "def change_width(ax, new_value) :\n",
    "    for patch in ax.patches :\n",
    "        current_width = patch.get_width()\n",
    "        diff = current_width - new_value\n",
    "\n",
    "        # we change the bar width\n",
    "        patch.set_width(new_value)\n",
    "\n",
    "        # we recenter the bar\n",
    "        patch.set_x(patch.get_x() + diff * .5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "fig_unbalanced = plt.figure(figsize=(5, 5))\n",
    "\n",
    "# Medias dos melhores params\n",
    "df_mean_unbalanced =  pd.DataFrame(mean_unbalanced).rename_axis('Métrica').reset_index().rename(columns = {0: 'Value'}) \n",
    "\n",
    "#plot\n",
    "ax = sns.barplot(x=\"Métrica\", y=\"Value\", data=df_mean_unbalanced, ci = None)\n",
    "plt.title('Branch and Bound - Sem Normalizacao - não balanceado')\n",
    "\n",
    "\n",
    "plt.errorbar(x=[0],y=mean_unbalanced[0],yerr= (acc_max_unbalanced - mean_unbalanced[0]) , fmt='none', color = 'black')\n",
    "plt.errorbar(x=[1],y=mean_unbalanced[1],yerr= (rec_max_unbalanced - mean_unbalanced[1]) , fmt='none', color = 'black')\n",
    "plt.errorbar(x=[2],y=mean_unbalanced[2],yerr= (pre_max_unbalanced - mean_unbalanced[2]) , fmt='none', color = 'black')\n",
    "\n",
    "fig_unbalanced.savefig('Branch_and_Bound-Sem_Normalizacao-nao_balanceado-SVC', bbox_inches='tight', dpi=600)\n",
    "\n",
    "ax.set(ylabel='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "fig_balanced = plt.figure(figsize=(5, 5))\n",
    "\n",
    "# Medias dos melhores params\n",
    "df_mean_balanced =  pd.DataFrame(mean_balanced).rename_axis('Métrica').reset_index().rename(columns = {0: 'Value'}) \n",
    "\n",
    "#plot\n",
    "ax = sns.barplot(x=\"Métrica\", y=\"Value\", data=df_mean_balanced, ci = None)\n",
    "plt.title('Branch and Bound - Sem Normalizacao - Balanceado')\n",
    "\n",
    "\n",
    "plt.errorbar(x=[0],y=mean_balanced[0],yerr= (acc_max_balanced - mean_balanced[0]) , fmt='none', color = 'black')\n",
    "plt.errorbar(x=[1],y=mean_balanced[1],yerr= (rec_max_balanced - mean_balanced[1]) , fmt='none', color = 'black')\n",
    "plt.errorbar(x=[2],y=mean_balanced[2],yerr= (pre_max_balanced - mean_balanced[2]) , fmt='none', color = 'black')\n",
    "\n",
    "fig_balanced.savefig('Branch_and_Bound-Sem_Normalizacao-balanceado-SVC', bbox_inches='tight', dpi=600)\n",
    "\n",
    "ax.set(ylabel='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armazena os Resultados para Gráfico Comparativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_save = '../../model_results/'\n",
    "\n",
    "# Leitura dos resultados anteriores\n",
    "all_models_results = pd.read_excel(path_to_save+'all_models_results.xlsx')\n",
    "\n",
    "for metrica in df_mean_unbalanced.index:\n",
    "    result = [\n",
    "    '7',\n",
    "    'SVC',\n",
    "    'Branch and Bound - Sem Normalização - Desbalanceado',\n",
    "    max_alpha_unbalanced,\n",
    "    df_mean_unbalanced.loc[metrica]['Métrica'],\n",
    "    df_mean_unbalanced.loc[metrica]['Value'],\n",
    "    \n",
    "    ]\n",
    "    aux_df = (pd.DataFrame(result).T).rename(columns = {0: 'Atividade', 1: 'Algoritmo', 2: 'Condicao',\n",
    "                                                        3: 'Melhores_Params', 4:'Metrica', 5: 'Valor'})\n",
    "    all_models_results = all_models_results.append(aux_df, ignore_index=True)\n",
    "\n",
    "# deleta da memoria\n",
    "del result, aux_df\n",
    "\n",
    "# Dataset Completo Balanceado\n",
    "for metrica in df_mean_balanced.index:\n",
    "    result = [\n",
    "    '7',\n",
    "    'SVC',\n",
    "    'Branch and Bound - Sem Normalização - Balanceado',\n",
    "    max_alpha_balanced,\n",
    "    df_mean_balanced.loc[metrica]['Métrica'],\n",
    "    df_mean_balanced.loc[metrica]['Value']\n",
    "    ]\n",
    "    aux_df = (pd.DataFrame(result).T).rename(columns = {0: 'Atividade', 1: 'Algoritmo', 2: 'Condicao', \n",
    "                                                        3: 'Melhores_Params', 4:'Metrica', 5: 'Valor'})\n",
    "    all_models_results = all_models_results.append(aux_df, ignore_index=True)\n",
    "\n",
    "display(all_models_results)\n",
    "\n",
    "# salva os resultados novos\n",
    "try:\n",
    "    all_models_results.to_excel(path_to_save+'all_models_results.xlsx', index=False)\n",
    "    print('Resultados salvos com sucesso')\n",
    "except Exception as e:\n",
    "    print('Erro {}'.format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
